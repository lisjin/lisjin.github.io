<!DOCTYPE html>
<html lang="en">
<head>

	<!-- Basic Page Needs
	–––––––––––––––––––––––––––––––––––––––––––––––––– -->
	<meta charset="utf-8">
	<title>Lisa Jin | Projects</title>
	<link rel="canonical" href="https://www.lisajin.com/projects.html">
	<meta name="description" content="">
	<meta name="author" content="">

	<!-- Mobile Specific Metas
	–––––––––––––––––––––––––––––––––––––––––––––––––– -->
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-LL55XS7830"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());
	  gtag('config', 'G-LL55XS7830');
	</script>

	<!-- FONT
	–––––––––––––––––––––––––––––––––––––––––––––––––– -->
	<link href="//fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

	<!-- CSS
	–––––––––––––––––––––––––––––––––––––––––––––––––– -->
	<link rel="stylesheet" href="static/css/normalize.css">
	<link rel="stylesheet" href="static/css/skeleton.css">
	<link rel="stylesheet" href="static/css/main.css">

	<!-- Favicon
	–––––––––––––––––––––––––––––––––––––––––––––––––– -->
	<link rel="icon" type="image/png" href="static/images/favicon.png">
</head>
<body>

<!-- Primary Page Layout
–––––––––––––––––––––––––––––––––––––––––––––––––– -->
<div class="container">
	<div class="row">
		<div class="offset-by-one three columns">
			<h4>Projects</h4>
		</div>
		<div class="seven columns">
			<ul class="nav-list">
				<li class="nav-item">
					<a class="nav-link u-pull-right" href="mailto:lisajin@rochester.edu" target="_blank">Contact</a>
				</li>
				<li class="nav-item">
					<a class="nav-link u-pull-right" href="static/lisajin-cv.pdf" target="_blank">CV</a>
				</li>
				<li class="nav-item">
					<a class="nav-link u-pull-right" href="index.html">Home</a>
				</li>
			</ul>
		</div>
	</div>
	<div class="row project-section">
		<div class="offset-by-one three columns">
			<p><strong>Advisor</strong>: Daniel Gildea</p>
			<a class="button" href="//arxiv.org/abs/2108.12304" target="_blank">Paper</a>
			<a class="button" href="//github.com/lisjin/lat-par" target="_blank">Code</a>
		</div>
		<div class="seven columns">
			<h6><strong>Latent Tree Decomposition Parsers for AMR-to-Text Generation</strong></h6>
			<p>To help close the structural gap between AMR graphs and their generated strings, we bias a graph encoder on the tree-like structure of AMRs. Since tree decompositions cluster graph edges into a hierarchy, we use them to augment AMR edge embeddings.</p>
			<p>Our baseline graph encoder encodes edges by running an RNN along shortest graph paths. Instead, our model computes node embeddings of an expected tree decomposition via the inside-outside algorithm. As each node clusters AMR edges, we propagate its embedding to the edges it covers.</p>
		</div>
	</div>
	<div class="row project-section">
		<div class="offset-by-one three columns">
			<p><strong>Advisor</strong>: Daniel Gildea</p>
			<a class="button" href="//arxiv.org/abs/2108.12300" target="_blank">Paper</a>
			<a class="button" href="//github.com/lisjin/td-attn" target="_blank">Code</a>
		</div>
		<div class="seven columns">
			<h6><strong>Tree Decomposition Attention for AMR-to-Text Generation</strong></h6>
			<p>Transformer-based graph encoders offer great flexibility in modeling pairwise vertex relationships. However, this expressiveness may contradict the goal of flattening AMR structure into a chain during text generation. We bias the encoder on graph-theoretic structures called <a href="//www.win.tue.nl/~nikhil/courses/2015/2WO08/treewidth-erickson.pdf" target="_blank">tree decompositions</a> that summarize AMR structure.</p>
			<p>We use parent, sibling, and same-depth relationships of nodes in an AMR's tree decomposition to locally restrict vertex attention. This hierarchy (i) lends sparsity to vertex state updates and (ii) bridges graph and string structure. We find that it boosts performance by 1.6 BLEU over a self-attentive baseline.</p>
		</div>
	</div>
	<div class="row project-section">
		<div class="offset-by-one three columns">
			<p><strong>Advisor</strong>: Daniel Gildea</p>
			<a class="button" href="//www.aclweb.org/anthology/2020.coling-main.181.pdf" target="_blank">Paper</a>
			<a class="button" href="//github.com/lisjin/gsp-enc" target="_blank">Code</a>
		</div>
		<div class="seven columns">
			<h6><strong>Generalized Shortest-Paths Encoders for AMR-to-Text Generation</strong></h6>
			<p>Recent neural AMR-to-text models apply Transformer self-attention to graph vertices rather than tokens. As a side-effect of this full pairwise attention graph structure may be lost. We build upon <a href="https://arxiv.org/abs/1911.07470" target="_blank">Cai and Lam (2020)</a> and include global graph paths in the attention mechanism to mitigate this.</p>
			<p>In place of pairwise-unique shortest paths, we expose the model to all graph paths using generalized shortest-paths algorithms. We experiment with both Floyd-Warshall and adjacency matrix multiplication, finding that the latter performs best in terms of BLEU and chrF++.</p>
		</div>
	</div>
	<div class="row project-section">
		<div class="offset-by-one three columns">
			<p><strong>Advisor</strong>: <a href="//feng-lab.github.io" target="_blank">Linqing Feng</a></p>
			<a class="button" href="//github.com/lisjin/dcan-tensorflow" target="_blank">Code</a>
		</div>
		<div class="seven columns">
			<h6><strong>DCAN for Cell Nuclei Image Segmentation</strong></h6>
			<p>I was supported by <a href="//www.eecs.umich.edu/ipan/" target="_blank">NSF IPAN</a> to work with Dr. Linqing Feng at KIST. We were interested in automating cell segmentation to study micro-scale brain connectivity. This is crucial to efficiently analyze large volumes of electron microscopy (EM) images of regions such as the hippocampus. To test the efficacy of such a method, I implemented TensorFlow code for the DCAN model on human U2OS cell <a href="//data.broadinstitute.org/bbbc/BBBC006/" target="_blank">images</a>.</p>
			<p><a href="//arxiv.org/pdf/1604.02677.pdf" target="_blank">DCAN</a> by Chen et al. builds upon the fully convolutional network (<a href="//arxiv.org/pdf/1411.4038.pdf" target="_blank">FCN</a>), in which <i>semantic</i> insight of deeper layers is combined with <i>locality</i> details of shallower layers. This end-to-end network can make per-pixel predictions for tasks like semantic segmentation.</p>
		</div>
	</div>
	<div class="row project-section">
		<div class="offset-by-one three columns">
			<p><strong>Advisor</strong>: <a href="//web.eecs.umich.edu/~dkoutra/" target="_blank">Danai Koutra</a></p>
			<a class="button" href="static/p40-jin.pdf" target="_blank">Paper</a>
			<a class="button" href="static/poster-jin.pdf" target="_blank">Poster</a>
			<a class="button" href="//github.com/lisjin/eco-viz" target="_blank">Code</a>
			<a class="button" href="static/p75.pdf" target="_blank">IEEE Bulletin</a>
		</div>
		<div class="seven columns">
			<h6><strong>ECOviz: Comparative Visualization of Time-Evolving Network Summaries</strong></h6>
			<p>Time-evolving graphs can be observed in a variety of domains, such as neuroscience and sociology. In connectomics, we can infer temporal networks from fMRI data; the nodes are voxels (volume units of neurons) and the edges are their thresholded associations. How can we track the evolution of domain-specific communities in such graphs?</p>
			<p>ECOviz is a system that summarizes and visualizes temporal network changes in a semi-supervised manner. Due to the small-worldness of brain networks, we used a subset of labeled nodes to inform <a href="//pdfs.semanticscholar.org/2448/9085f90aa5d262c21ef66c33dabaf413667e.pdf" target="_blank">TimeCrunch</a>, a dynamic graph summarization algorithm. In addition to showing the topology of summary structures, ECOviz allows users to compare the effects of preprocessing parameters (i.e., threshold and time interval granularity).</p>
		</div>
	</div>
	<div class="row project-section">
		<div class="offset-by-one three columns">
			<p><strong>Advisor</strong>: <a href="http://www.andrewdeorio.com" target="_blank">Andrew DeOrio</a></p>
			<p><strong>Sponsors</strong>: <a href="//medicine.umich.edu/dept/human-genetics/dana-schlegel-ms-mph-cgc" target="_blank">Dana Schlegel</a>, <a href="//medicine.umich.edu/dept/ophthalmology/k-thiran-jayasundera-md-facs-frcsc-franzco" target="_blank">Thiran Jayasundera</a></p>
			<p><strong>Collaborators</strong>: Ajaay Chandrasekaran, Edmond Cunningham, Levin Kim, Wenlu Yan, Xinghai Zhang, Yaman Abdulhak</p>
			<a class="button" href="static/MDP_DesignExpo.pdf" target="_blank">Poster</a>
		</div>
		<div class="seven columns">
			<h6><strong>Cloud-Based Ocular Disease Diagnosis</strong></h6>
			<p>Sponsored by the <a href="//www.umkelloggeye.org" target="_blank">Kellogg Eye Center</a>, this was a two-semester project in the Multidisciplinary Design Program (<a href="//mdp.engin.umich.edu" target="_blank">MDP</a>). Retinal dystrophies are inheritable disorders that require expensive genetic tests and medical expertise to diagnose. Given patient inheritance and history data, we built a web app with a data-driven model to predict retinal dystrophy diagnosis.</p>
			<p>I contributed to the web app prototype to (1) collect patient data from a user and (2) visualize output from a predictive model built by my teammates. This model first predicted inheritance pattern, then paired this with patient history to output the final diagnosis via an RBF kernel SVM.</p>
		</div>
	</div>
	<div class="row project-section">
		<div class="offset-by-one three columns">
			<p><strong>Advisor</strong>: <a href="//lsa.umich.edu/psych/people/faculty/junz.html" target="_blank">Jun Zhang</a></p>
			<p><strong>Collaborator</strong>: Yinbin Lei</p>
			<a class="button" href="static/FCA_Report.pdf" target="_blank">Report</a>
			<a class="button" href="//github.com/lisjin/fca-viz" target="_blank">Code</a>
		</div>
		<div class="seven columns">
			<h6><strong>Visualization of Formal Concepts</strong></h6>
			<p>Under Prof. Jun Zhang and visiting faculty Yinbin Lei, this was an independent study project in the psychology department. Though algorithms to extract concept hierarchies exist, I contributed code to visualize and query the computed lattice through set operations. This work was motivated by analysis of concept formation data.</p>
			<p>Formal concept analysis (FCA) is a method for deriving a concept hierarchy from a table of object-attribute relations. A formal concept is composed of a set of objects and their attributes. Concepts can be partially ordered into a lattice, or hierarchy, such that edges represent set closures.</p>
		</div>
	</div>
</div>

<!-- JS
–––––––––––––––––––––––––––––––––––––––––––––––––– -->

<!-- End Document
–––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
